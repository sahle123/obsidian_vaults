# Large Language Models (LLMs)

## Available Models (2023)

### [[Audio-Speech Recognition]]
### [[Image Generation]]
### [[Text Generation]]
### [[Multi-Modal]]
# Uncategorized

## Basic Terminology

* _Completion_ - The output of an LLM. It can be in many different media formats such as text, image, audio, etc...
* _Hallucination_ - Often used in the context of text Completions, a hallucination is false or inaccurate information that is stated to be fact. A fairly common issue, especially when asking fantastical questions.
* _Prompt_ - The input of an LLM. It is generally in the form of text.
* _Tokenization_ - Converting a string of characters into _tokens_. A _token_ is a chunk of text of varying length. _Tokens_ are then converted into integer indices which are essentially the encoding of the text.
## AI History

* __Artificial Intelligence__ - (1956) Field of computer science that seeks to create intelligent machines that can replicate or exceed human intelligence. This works with large knowledge bases maintained by experts. Highly unscalable.
* __Machine Learning__ - (1997) A subset of AI that enables machines to 'learn' from existing data and improve upon the data to make decisions or predictions. This takes a statistical approach.
* __Deep Learning__ - (2017) A machine learning technique in which layers of neural networks are used to process data and make decisions. These are black-box constructs that can't easily be explained once the model is trained.
* __Generative AI__ - (2021) A subset of deep-learning capable of generating images, text, or other media using generative models. Generative AI models learn the patterns and structure of their input training data and then generate new data that has similar characteristics. This approach heavily utilizes _transformer-based deep neural networks_.
